apiVersion: v1
# Vamos a crear un objecto de tipo "Pod"
kind: Pod
metadata:
  # nombre del pod, esto lo veremos cuando ejecutemos kubectl get pods
  name: demo-cuda
spec:
  # Que hago si se muere el pod:
  #     Never - no lo reinicies
  #     Always - siempre reinicialo
  restartPolicy: Never
  # denro del Pod puede haber 1 o mas contenedores
  containers:
    # Identificador del primer contenedor del Pod
    # En caso de haber multiples contenedores este es el nombre
    # con el que identificaremos a este contenedor
    - name: demo-cuda
      # La imagen que utilizara el contenedor
      # Si no se especifica un registro, entonces asume que la
      # imagen se encuentra en hub.docker.com
      # projecto/imagen:etiqueta
      # https://hub.docker.com/layers/nvidia/cuda/11.0.3-devel-ubi8/images/sha256-8da004f01e8cfe7d4fcdd987567c8a0a4ca8fda6fcfd5333913bd92d0fce8691?context=explore
      image: "nvidia/cuda:11.0.3-devel-ubi8"
      # comando a ejecutar una vez desplegado el contenedor. 
      # Normalmente se especifica para sobreescribir el punto de entrada de la imagen
      command: ["sh", "-c", "sleep infinity"]
      # Recursos requeridos
      resources:
        limits:
          memory: 4G
          cpu: 2
          nvidia.com/gpu: 1
        # (Opcional): recursos minimos
        requests:
          memory: 2G
          cpu: 1
          nvidia.com/gpu: 1
      # Donde montar los volumenes listados debajo
      volumeMounts:
       - mountPath: /s3
         name: s3-cudi
  # volumenes que quiero utilizar en mi contenedor
  volumes:
   - name: s3-cudi
     # Tipo de volumen
     persistentVolumeClaim:
       # Nombre de la volumen (PVC) en el cluster
       # Este es el nombre de nuestro S3
       claimName: example-dataset
       readOnly: false
  # (Opcional) Nodo en donde queremos ejecutar
  # si no se especifica k8s encontrara un nodo adecaudo segun los requerimientos
  nodeSelector:
    kubernetes.io/hostname: atocatl-gpu-04.lamod.unam.mx
